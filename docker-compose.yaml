services:
  # Service Zookeeper (nécessaire pour Kafka)
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.1
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    restart: unless-stopped

  # Kafka pour la gestion des flux de données
  kafka:
    image: confluentinc/cp-kafka:7.4.1
    depends_on:
      - zookeeper    
    restart: unless-stopped
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  # Interface web pour visualiser les topics et les messages dans Kafka
  kafdrop:
    image: obsidiandynamics/kafdrop:latest
    depends_on:
      - kafka
    ports:
      - "9000:9000"
    environment:
      KAFKA_BROKERCONNECT: kafka:9092

  # MongoDB pour stocker les données
  mongodb:
    image: mongo:6.0
    restart: unless-stopped
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: example
    ports:
      - "27017:27017"
    volumes:
      - mongodb-data-volume:/data/db
      - ./init-mongo:/docker-entrypoint-initdb.d

  # Interface web pour MongoDB
  mongo-express:
    image: mongo-express:1.0.0-alpha.4
    restart: unless-stopped
    environment:
      ME_CONFIG_MONGODB_ADMINUSERNAME: root
      ME_CONFIG_MONGODB_ADMINPASSWORD: example
      ME_CONFIG_MONGODB_SERVER: mongodb
    ports:
      - "8081:8081"

  # MailDev pour tester les e-mails envoyés par Airflow
  maildev:
    image: maildev/maildev
    ports:
      - "1080:1080" # Interface web MailDev
      - "1025:1025" # Port SMTP pour capturer les e-mails

  # Consumer, service qui consomme les messages de Kafka et les enregistre dans MongoDB
  consumer-openweather:
    build:
      context: ./consumer-openweather  # Chemin du Dockerfile du consumer
    restart: unless-stopped  # Redémarre le service si il échoue
    environment:
      KAFKA_SERVER: ${KAFKA_SERVER}  # Serveur Kafka
      KAFKA_WEATHER_TOPIC: ${KAFKA_WEATHER_TOPIC}  # Topic Kafka à consommer
      MONGO_URI: ${MONGO_URI}  # URI de connexion à MongoDB
      MONGO_DB_WEATHER: ${MONGO_DB_WEATHER}  # Nom de la base de données MongoDB
      MONGO_COLLECTION_WEATHER: ${MONGO_COLLECTION_WEATHER}  # Nom de la collection MongoDB

  # Producer
  producer-openweather:
    build:
      context: ./producer-openweather  # Chemin du Dockerfile du consumer
    restart: unless-stopped  # Redémarre le service si il échoue
    environment:
      KAFKA_SERVER: ${KAFKA_SERVER}  # Serveur Kafka
      KAFKA_WEATHER_TOPIC: ${KAFKA_WEATHER_TOPIC}  # Topic Kafka à consommer
      API_WEATHER_URL: ${API_WEATHER_URL}  # URL de l'API de météo (par exemple, OpenWeather)
      API_WEATHER_CITY_IDS: ${API_WEATHER_CITY_IDS}  # Liste des IDs des villes pour la récupération des données
      API_WEATHER_LANG: ${API_WEATHER_LANG}  # Langue des données
      API_WEATHER_UNITS: ${API_WEATHER_UNITS}  # Unités des données
      API_WEATHER_KEY: ${API_WEATHER_KEY}  # Clé API pour accéder à l'API
      FETCH_INTERVAL: ${FETCH_INTERVAL}  # Intervalle de temps pour récupérer les données (en secondes)

  # Streamlit, service de visualisation des données météo avec une interface web
  streamlit:
    build: ./streamlit  # Chemin du Dockerfile de Streamlit
    environment:
      MONGO_URI: ${MONGO_URI}  # URI de connexion à MongoDB
      MONGO_DB_WEATHER: ${MONGO_DB_WEATHER}  # Nom de la base de données MongoDB
      MONGO_COLLECTION_WEATHER: ${MONGO_COLLECTION_WEATHER}  # Nom de la collection MongoDB
      FETCH_INTERVAL: ${FETCH_INTERVAL}  # Intervalle de temps pour récupérer les données (en secondes)
    ports:
      - "8501:8501"  # Expose l'application Streamlit sur le port 8501
    depends_on:
      - mongodb  # Streamlit dépend de MongoDB pour accéder aux données

volumes:
  postgres-data-volume:
  mongodb-data-volume:
